{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-K81jKMdefgh",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/jax/lib/xla_bridge.py:130: UserWarning: No GPU/TPU found, falling back to CPU.\n",
      "  warnings.warn('No GPU/TPU found, falling back to CPU.')\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from jax import grad, vmap, jit, partial, random\n",
    "import numpy as onp\n",
    "from jax.experimental import optimizers\n",
    "key = random.PRNGKey(0)\n",
    "import pickle\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from NODE_fns import NODE_lm2sigma_vmap, init_params, node_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'P12AC1_sy'\n",
    "dataset_name = 'P12AC1_sy'\n",
    "\n",
    "with open('training_data/' + dataset_name + '.npy', 'rb') as f:\n",
    "    lamb, sigma_gt = np.load(f,allow_pickle=True)\n",
    "n_data = lamb.shape[0]\n",
    "weights1 = onp.ones([n_data,1]) # Weight of the loss components. Useful sometimes.\n",
    "weights2 = onp.ones([n_data,1])\n",
    "if dataset_name == 'rubber20UT_ET_PS':\n",
    "    weights2[42:] = 0 #Ignore the loss on sigma_yy in strip-biaxial data since we don't have it.\n",
    "if dataset_name == 'rubber50UT_ET_PS':\n",
    "    weights2[33:] = 0\n",
    "sigma_gt = np.hstack((sigma_gt,weights1,weights2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find normalization constants\n",
    "lm1,lm2 = lamb.T\n",
    "lm3 = 1/(lm1*lm2)\n",
    "\n",
    "z = np.zeros_like(lm1)\n",
    "F = np.array([[lm1, z, z],\n",
    "              [z, lm2, z],\n",
    "              [z, z, lm3]])\n",
    "F = np.mean(F, axis=2)\n",
    "C = np.einsum('ji,jk->ik', F, F)\n",
    "Cinv = np.linalg.inv(C)\n",
    "C2 = np.einsum('ij,jk->ik', C, C)\n",
    "I1 = C[0,0] + C[1,1] + C[2,2]\n",
    "I2 = 0.5*(I1**2 - np.trace(C2))\n",
    "\n",
    "sigma = np.mean(sigma_gt, axis=0)\n",
    "sigma = np.array([[sigma[0], 0, 0],\n",
    "                  [0, sigma[1], 0],\n",
    "                  [0, 0,        0]])\n",
    "S = np.einsum('ij,jk,kl', np.linalg.inv(F), sigma, np.linalg.inv(F).T)\n",
    "\n",
    "a = np.array([[2, 2*(I1-C[0,0]), Cinv[0,0]],\n",
    "              [2, 2*(I1-C[1,1]), Cinv[1,1]],\n",
    "              [2, 2*(I1-C[2,2]), Cinv[2,2]],])\n",
    "b = np.array([S[0,0], S[1,1], S[2,2]])\n",
    "[Psi1, Psi2, p] = np.linalg.lstsq(a,b)[0]\n",
    "norm = [I1-3, I2-3, np.abs(Psi1), np.abs(Psi2)]\n",
    "norm = [1.0,1.0,1.0,1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fze3LRWYMjou",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def loss(params, lamb, sigma_gt):\n",
    "    sigma_pr = NODE_lm2sigma_vmap(lamb, params, norm)\n",
    "    pr = sigma_pr[:,0]\n",
    "    gt = sigma_gt[:,0]\n",
    "    weight = sigma_gt[:,2] # Now I am just using this weight to accomodate the strip-bi data without sigma_yy info.\n",
    "    \n",
    "    loss_MSE1 = np.mean((pr - gt)**2*weight)\n",
    "                          \n",
    "    pr = sigma_pr[:,1]\n",
    "    gt = sigma_gt[:,1]\n",
    "    weight = sigma_gt[:,3]\n",
    "    loss_MSE2 = np.mean((pr - gt)**2*weight)\n",
    "    return  loss_MSE1 + loss_MSE2\n",
    "\n",
    "@partial(jit, static_argnums=(0,))\n",
    "def step(loss, i, opt_state, X_batch, Y_batch):\n",
    "    params = get_params(opt_state)\n",
    "    g = grad(loss)(params, X_batch, Y_batch)\n",
    "    return opt_update(i, g, opt_state)\n",
    "\n",
    "def train(loss, X, Y, opt_state, key, nIter = 10000, batch_size = 10):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for it in range(nIter):\n",
    "        key, subkey = random.split(key)\n",
    "        idx_batch = random.choice(subkey, X.shape[0], shape = (batch_size,), replace = False)\n",
    "        opt_state = step(loss, it, opt_state, X[idx_batch,:], Y[idx_batch,:])         \n",
    "        if (it+1)% 1000 == 0:\n",
    "            params = get_params(opt_state)\n",
    "            train_loss_value = loss(params, X, Y)\n",
    "            train_loss.append(train_loss_value)\n",
    "            to_print = \"it %i, train loss = %e\" % (it+1, train_loss_value)\n",
    "            print(to_print)\n",
    "    return get_params(opt_state), train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bOIkF_yNqrf",
    "outputId": "a0d3f88b-cd08-4767-9e5b-5e0beb062e69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize parameters and the optimizer\n",
    "layers = [2, 5, 5, 1]\n",
    "params = []\n",
    "for i in range(10):\n",
    "    key, subkey = random.split(key)\n",
    "    params.append(init_params(layers, key)) # 10 NNs in total\n",
    "I_weights = np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "theta = 1.0\n",
    "Psi1_bias = -3.0\n",
    "Psi2_bias = -3.0\n",
    "params.extend([I_weights, theta, Psi1_bias, Psi2_bias])\n",
    "\n",
    "opt_init, opt_update, get_params = optimizers.adam(5.e-5) #Original: 1.e-4\n",
    "opt_state = opt_init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/jax/numpy/lax_numpy.py:1674: FutureWarning: jax.numpy reductions won't accept lists and tuples in future versions, only scalars and ndarrays\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 1000, train loss = 3.881142e+02\n",
      "it 2000, train loss = 3.709634e+00\n",
      "it 3000, train loss = 2.516510e+00\n",
      "it 4000, train loss = 2.157014e+00\n",
      "it 5000, train loss = 1.635494e+00\n",
      "it 6000, train loss = 9.750501e-01\n",
      "it 7000, train loss = 8.105523e-01\n",
      "it 8000, train loss = 7.369821e-01\n",
      "it 9000, train loss = 6.658425e-01\n",
      "it 10000, train loss = 5.734418e-01\n",
      "it 11000, train loss = 4.547409e-01\n",
      "it 12000, train loss = 3.216647e-01\n",
      "it 13000, train loss = 2.023445e-01\n",
      "it 14000, train loss = 1.144601e-01\n",
      "it 15000, train loss = 6.263650e-02\n",
      "it 16000, train loss = 3.418854e-02\n",
      "it 17000, train loss = 1.869997e-02\n",
      "it 18000, train loss = 1.038953e-02\n",
      "it 19000, train loss = 5.942764e-03\n",
      "it 20000, train loss = 3.559063e-03\n",
      "it 21000, train loss = 2.259431e-03\n",
      "it 22000, train loss = 1.573314e-03\n",
      "it 23000, train loss = 1.174472e-03\n",
      "it 24000, train loss = 9.429758e-04\n",
      "it 25000, train loss = 7.962052e-04\n",
      "it 26000, train loss = 6.889570e-04\n",
      "it 27000, train loss = 6.082064e-04\n",
      "it 28000, train loss = 5.433199e-04\n",
      "it 29000, train loss = 4.903041e-04\n",
      "it 30000, train loss = 4.464489e-04\n",
      "it 31000, train loss = 4.091132e-04\n",
      "it 32000, train loss = 3.734954e-04\n",
      "it 33000, train loss = 3.425601e-04\n",
      "it 34000, train loss = 3.160705e-04\n",
      "it 35000, train loss = 2.939353e-04\n",
      "it 36000, train loss = 2.685948e-04\n",
      "it 37000, train loss = 2.884124e-04\n",
      "it 38000, train loss = 2.328281e-04\n",
      "it 39000, train loss = 2.064431e-04\n",
      "it 40000, train loss = 2.000822e-04\n",
      "it 41000, train loss = 1.895570e-04\n",
      "it 42000, train loss = 1.849470e-04\n",
      "it 43000, train loss = 6.076886e-04\n",
      "it 44000, train loss = 1.580283e-04\n",
      "it 45000, train loss = 7.475540e-03\n",
      "it 46000, train loss = 1.705505e-04\n",
      "it 47000, train loss = 5.413193e-04\n",
      "it 48000, train loss = 1.406206e-04\n",
      "it 49000, train loss = 1.326215e-04\n",
      "it 50000, train loss = 1.298638e-04\n"
     ]
    }
   ],
   "source": [
    "#%%timeit -r 0 \n",
    "batch_size = np.min([100,lamb.shape[0]])\n",
    "params, train_loss, val_loss = train(loss,lamb, sigma_gt, opt_state, key, nIter = 50000, batch_size = batch_size) #Original 100000\n",
    "with open('savednet/' + model_name + '.npy', 'wb') as f:\n",
    "    pickle.dump(params, f)\n",
    "with open('savednet/' + model_name + '_norm.npy', 'wb') as f:\n",
    "    pickle.dump(norm, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa190c0cb20>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sigma_pr = NODE_lm2sigma_vmap(lamb, params, norm)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(lamb[:,1], sigma_gt[:,0], '.')\n",
    "ax.plot(lamb[:,1], sigma_pr[:,0], '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many indices for array: 1 non-None/Ellipsis indices for dim 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bcf9d8c56a9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/CloudStorage/OneDrive-purdue.edu/Research/node_kuhl/NODE_fns.py\u001b[0m in \u001b[0;36mnode_traj\u001b[0;34m(params, inp)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNODE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/jax/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx)\u001b[0m\n\u001b[1;32m   3646\u001b[0m   \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3647\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3648\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3650\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/jax/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx)\u001b[0m\n\u001b[1;32m   3653\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/jax/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx)\u001b[0m\n\u001b[1;32m   3737\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m   \u001b[0;31m# Remove ellipses and add trailing slice(None)s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3739\u001b[0;31m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_canonicalize_tuple_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m   \u001b[0;31m# Check for advanced indexing:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/jax/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_canonicalize_tuple_index\u001b[0;34m(arr_ndim, idx)\u001b[0m\n\u001b[1;32m   3999\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen_without_none\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0marr_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Too many indices for array: {} non-None/Ellipsis indices for dim {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4001\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_without_none\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4002\u001b[0m   \u001b[0mellipses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m   \u001b[0mellipsis_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mellipses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Too many indices for array: 1 non-None/Ellipsis indices for dim 0."
     ]
    }
   ],
   "source": [
    "inp = np.linspace(0,3)\n",
    "out = node_traj(params[0],inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Constitutive_NeuralODE.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
